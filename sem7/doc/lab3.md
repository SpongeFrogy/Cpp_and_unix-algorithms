# ЛР #3: Алгоритм работы с графами (моделирование транспортной системы)

## Цель

Познакомить студента с инструментами, направленными на решение задач, использующих графовые модели.

## Задача

Моделирование сложных транспортных процессов города, выявление узких участков, а также
формирование предложений по оптимизации.

__Дано__: На изображении отображены перекрестки, которые рассматривать для решения задачи.
В качестве агентов (автомобилей) и маршрутов их перемещения использовать придуманные
данные, отраженные в отчете по лабораторной работе (предусмотреть часы пик утром и
вечером).

![img](/sem7/lab3/map.png)

## Задача 1: Необходимо определить TOP-10 самых загруженных участков

между перекрестками, а также время на «рассасывание» этого затора.
Отображать такие параметры, как:
количество агентов (автомобилей) на участке;
процент загруженности участка;
длительность высокой загруженности (более 90%).

### Решение задачи 1

Кратко опишем модель:

Основные классы:

```python
class Road:
    def __init__(self, c0: CrossRoad, c1: CrossRoad, name: str, s0={}, s1={}):
        ...

    def add_car(self, car: Car):
        ...

    def draw(self, screen: pygame.display):
        ...
```

```python
class CrossRoad:
    def __init__(self, pos: tuple[int, int]):
        ...

    def add_road(self, road: Road, signal: Signal) -> Road:
        ...

    def update_signal(self, t, dt):
        ...

    def draw(self, screen):
        ...
```

```python
class Signal:
    def __init__(self, crossroad: CrossRoad, road: Road, timing: tuple[int, int], signal: bool, time: int):
        ...

    def update(self, dt: int) -> bool:
        ...

    @property
    def _color(self):
        ...

    def draw(self, screen):
        ...
```

```python
class Car:
    def __init__(self, road: Road, v: int, pos: float | int, direction: bool = True):
        ...

    def _go(self, dt: float):
        ...

    def change_road(self):
        ...

    def update(self, dt):
        ...

    def draw(self, screen):
        ...
```

```python
class InitCarGenerator:
    def __init__(self, road: Road, v=5, n_cars_true: int = 10, n_cars_false: int | None = None):
        ...

    def generate(self):
        ...
```

```python
class City:
    def __init__(self) -> None:
        ...

    def add_road(self, road: Road):
        ...

    def add_roads(self, list: list[Road]):
        ...

    def add_c_road(self, crossroad: CrossRoad):
        ...

    def add_c_roads(self, list: list[CrossRoad]):
        ...

    def add_init_car_gen(self, gen: InitCarGenerator):
        ...

    def add_init_car_gens(self, list: list[InitCarGenerator]):
        ...

    def generate(self):
        ...

    def reset(self):
        ...

    def update_mean_v(self):
        ...

    def loop(self, dt=0.1, t_max=1000):
        """
        return time, score : list[float], list[float]
        """
        ...

    def loop_draw(self, score_font_params=(None, 24), road_font_params=(None, 13), dt=0.1, condition=lambda x: True):
        ...

    def loop_plot(self, dt=0.1, condition=lambda x: True):
        ...
```

Уточнения:

1. Изначально на каждой дороге генерируется количество машин, пропорциональное длине дороги.
2. На одной дороге все машины двигаются с одной скоростью, пропорциональной длине дороги.
3. На перекрестке, если горит зеленый, машина выбирает следующую дорогу из всех дорога перекрестка, кроме настоящей дороги, и выбирает с вероятностью, обратно пропорциональной длине дороги машины. Сделано это для дальнейшей оптимизации.

## Задача 2: С помощью сформированной модели предложить варианты решения заторов

между перекрестками, а также время на «рассасывание» этого затора.
Отображать такие параметры, как:
количество агентов (автомобилей) на участке;
процент загруженности участка;
длительность высокой загруженности (более 90%).

### Решение задачи 2

Основные классы:

```python
from city import *
from copy import deepcopy
from concurrent.futures import ThreadPoolExecutor
from multiprocessing import Process, Manager


def make_signal_params(cs: list[CrossRoad], timings: list[int, int]):
    res = {}
    for i, timing in zip(range(len(cs)), timings):
        res[i] = [{"timing": timing,
                   "signal": True,
                   "time": 0},
                  {"timing": timing,
                   "signal": False,
                   "time": timing[0]}]
    return res


class Model:
    def __init__(self, timings: list[int, int]) -> None:
        cs = [...]   # 22

        signal_params = make_signal_params(cs, timings)

        rs = [...]

        iGens = [InitCarGenerator(
            r, n_cars_true=int(r.length//10)) for r in rs]

        SPB = City()

        SPB.add_roads(rs)
        SPB.add_c_roads(cs)

        SPB.add_init_car_gens(iGens)

        self.city = SPB

    def simulate_one(self, t_max=1000):
        city = deepcopy(self.city)
        return city.loop(t_max=t_max)
```

```python
import optuna
from optuna_dashboard import run_server
from model import Model
import numpy as np


def objective(trial):
    params = [None]*22
    for i in range(22):
        new = trial.suggest_float(f"p{i}", 0, 10)
        params[i] = (new, 10-new)
    model = Model(params)
    res = model.simulate_one()
    return res[1][-1]

storage = optuna.storages.InMemoryStorage()
study = optuna.create_study(storage=storage, study_name="TPE of model optimize", direction="maximize", sampler=optuna.samplers.TPESampler())
study.optimize(objective, n_trials=200, n_jobs=3)

run_server(storage)
```

В коде выше использовался Tree-structured Parzen Estimator (TPE) - метод оптимизации, часто используемый в нейронных сетях для настройки гиперпараметров модели.

Метод Tree-structured Parzen Estimator (TPE) - это алгоритм последовательного использования модели (Sequential Model based optimization, SMBO), который используется для оптимизации гиперпараметров в машинном обучении.

TPE был представлен в работах Bergstra, Yamins и Cox, в которых они исследовали чёрно-ящичные функции. Идея TPE состоит в замене традиционной функции проб и ошибок, которую можно увидеть в алгоритмах типа grid search или random search, на "модель" проб и ошибок.

Работа TPE алгоритма включает в себя следующие основные шаги:

Моделирование P(x|y), где x - гиперпараметры модели, а y - результаты. TPE делает это, сравнивая "хорошие" результаты с "плохими" и на практике проводит моделирование двух раздельных плотностей, где одна для хороших результатов и другая для плохих.

Генерация новых выборок. TPE выбирает следующий набор гиперпараметров, используя модель P(x|y) для выбора распределений. Это достигается путём минимизации следующей функции: l(x) = P(y | x < y*) / P(x), где y* является пороговым значением, которое разделяет хорошие и плохие результаты.

Обновление модели. После получения нового результата алгоритм обновляет p(x|y) и повторяет процесс.

Для всех пар (x, y), если y меньше порогового значения, x считается хорошим значением. Если y больше порогового значения, тогда x считается плохим значением. Все "хорошие" и "плохие" значения x обрабатываются TPE и используются для следующих итераций.

Как SMBO-алгоритмы, TPE работает эффективнее на пространствах с большим количеством гиперпараметров, и обычно выигрывает у обычных методов подбора гиперпараметров, таких как решетчатый поиск (grid search) или случайный поиск (random search).

- Сильные стороны:

  - использует результаты предыдущих итераций;
  - может работать с зависимостями между гиперпараметрами, в которых один гиперпараметр не будет рассматриваться, если другой не примет какое-то определённое значение (например, число нейронов во втором слое нейросети нужно перебирать, если параметр «число слоёв» имеет значение не менее двух);
  - имеет линейную сложность по числу гиперпараметров (в отличие от БО);
  - не требует специальных хаков для работы с категориальными признаками, так как каждый гиперпараметр в этом алгоритме имеет своё отдельное одномерное распределение, и не нужно строить сложное совместное распределение всех гиперпараметров (как в БО);
  - достигает высоких результатов по качеству, довольно часто используется в соревнованиях.
- Слабые стороны:

  - не может моделировать неявные зависимости между гиперпараметрами (те, которые юзер не задал с помощью дерева);
  - хотя сложность и меньше, чем у БО, может работать довольно медленно даже на не очень большом числе гиперпараметров.

Подробнее можно прочитать [сдесь](https://academy.yandex.ru/handbook/ml/article/podbor-giperparametrov)

### Результаты оптимизации

Параметры оптимизации:

```python
new = trial.suggest_float(f"p{i}", 0, 10)
params[i] = (new, 10-new)
```

![img](/sem7/lab3/trials.png)

![img](/sem7/lab3/importance.png)

Результаты моделирования, если все параметры равны `5`
![img](/sem7/lab3/review_all_green.png)

Результаты моделирования после оптимизации:
![img](/sem7/lab3/review_opt.png)

### Для задач 1 и 2 рассчитать и обосновать оценку вычислительной и ёмкостной сложности

- Оценка сложности (Computational Complexity):

  - Временная сложность TPE в основном зависит от количества итераций оптимизации и размера выборки гиперпараметров. Обычно она имеет логарифмическую зависимость от размера пространства гиперпараметров и количества итераций, что делает ее относительно эффективной. В большинстве случаев, TPE требует меньше вычислительных ресурсов по сравнению с полным перебором (grid search) или случайным поиском (random search), особенно в больших пространствах гиперпараметров.

- Требования к памяти (Memory Requirements):

  - Память, занимаемая TPE, зависит от размера пространства гиперпараметров и количества итераций оптимизации. TPE требует хранения и обновления модели оценки плотности вероятности, что может потребовать некоторого объема памяти, особенно при работе с большими объемами данных или сложными моделями. Однако обычно требования к памяти TPE считаются умеренными по сравнению с другими методами оптимизации гиперпараметров, такими как случайный поиск или полный перебор.
  
Точные численные значения сложности и требований к памяти могут варьироваться в зависимости от конкретных параметров оптимизации (например, количество итераций, размер пространства гиперпараметров) и библиотеки, используемой для реализации TPE.
